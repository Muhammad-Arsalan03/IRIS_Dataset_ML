# -*- coding: utf-8 -*-
"""ML_Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mWx0fYyiDb2kGg3n0TzU2lMOrvJEyii5
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


from warnings import filterwarnings
filterwarnings(action='ignore')

iris=pd.read_csv("/content/iris.csv")
print(iris)

print(iris.shape)

print(iris.describe())



#Checking for null values
print(iris.isna().sum())
print(iris.describe())



iris.head(150)

fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.axis('equal')
l = ['Versicolor', 'Setosa', 'Virginica']
s = [50,50,50]
ax.pie(s, labels = l,autopct='%1.2f%%')
plt.show()

iris.hist('sepal.length')
iris.hist('sepal.width')
iris.hist('petal.length')
iris.hist('petal.width')

from sklearn.linear_model import LogisticRegression 
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm
from sklearn import metrics
from sklearn.tree import DecisionTreeClassifier

train, test = train_test_split(iris, test_size = 0.25)
print(train.shape)
print(test.shape)



train_X = train[['sepal.length', 'sepal.length', 'petal.length','petal.width']]
train_y = train.variety

test_X = test[['sepal.length', 'sepal.length', 'petal.length','petal.width']]
test_y = test.variety

train_X.head()

#Using LogisticRegression
model = LogisticRegression()
model.fit(train_X, train_y)
prediction = model.predict(test_X)
accuracy1=metrics.accuracy_score(prediction,test_y)
print(accuracy1)
print('Accuracy:',metrics.accuracy_score(prediction,test_y))

#Confusion matrix
from sklearn.metrics import confusion_matrix,classification_report
confusion_mat = confusion_matrix(test_y,prediction)
print("Confusion matrix: \n",confusion_mat)
print(classification_report(test_y,prediction))

#Using Support Vector
from sklearn.svm import SVC
model1 = SVC()
model1.fit(train_X,train_y)

pred_y = model1.predict(test_X)

from sklearn.metrics import accuracy_score
accuracy2=accuracy_score(test_y,pred_y)
print (accuracy2)
print("Acc=",accuracy_score(test_y,pred_y))

#Using KNN Neighbors
from sklearn.neighbors import KNeighborsClassifier
model2 = KNeighborsClassifier(n_neighbors=5)
model2.fit(train_X,train_y)
y_pred2 = model2.predict(test_X)

from sklearn.metrics import accuracy_score
accuracy3=accuracy_score(test_y,y_pred2)
print(accuracy3)
print("Accuracy Score:",accuracy_score(test_y,y_pred2))

#Using GaussianNB
from sklearn.naive_bayes import GaussianNB
model3 = GaussianNB()
model3.fit(train_X,train_y)
y_pred3 = model3.predict(test_X)

from sklearn.metrics import accuracy_score
accuracy4=accuracy_score(test_y,y_pred3)
print(accuracy4)
print("Accuracy Score:",accuracy_score(test_y,y_pred3))

#Using Decision Tree
from sklearn.tree import DecisionTreeClassifier
model4 = DecisionTreeClassifier(criterion='entropy',random_state=7)
model4.fit(train_X,train_y)
y_pred4 = model4.predict(test_X)

from sklearn.metrics import accuracy_score
accuracy5=accuracy_score(test_y,y_pred4)
print(accuracy5)
print("Accuracy Score:",accuracy_score(test_y,y_pred4))

#USILNG random forest classifier 
from sklearn.ensemble import RandomForestClassifier 
clfr= RandomForestClassifier(random_state = 100)

# Performing training 

clfr.fit(train_X, train_y)

#making prediction 

Y_pred=clfr.predict(test_X)
accuracy6= metrics.accuracy_score(test_y, Y_pred)
print("Accuracy:",metrics.accuracy_score(test_y, Y_pred))

results = pd.DataFrame({'Model': ['Logistic Regression','Support Vector Machines', 'Naive Bayes','KNN' ,
                                  'Decision Tree'],'Score': [accuracy1,accuracy2, accuracy3, 
                                                                            accuracy4, accuracy5]})

result_df = results.sort_values(by='Score', ascending=False)
result_df = result_df.set_index('Score')
result_df.head(9)